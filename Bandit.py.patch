--- a/Bandit.py
+++ b/Bandit.py
@@ -10,6 +10,8 @@
 
 
 class CustomFormatter(logging.Formatter):
+    """Custom log formatter to enhance log output readability."""
     # Defining custom log formatting
     grey = "\x1b[38;20m"
     yellow = "\x1b[33;20m"
@@ -26,6 +28,14 @@
     }
 
     def format(self, record):
+        """
+        Format the log messages based on severity levels.
+
+        Args:
+            record (logging.LogRecord): Log record which contains all the details being logged.
+
+        Returns:
+            str: Formatted log message.
+        """
         log_fmt = self.FORMATS.get(record.levelno)
         formatter = logging.Formatter(log_fmt)
         return formatter.format(record)
@@ -37,6 +47,8 @@
 
 
 class Bandit(ABC):
+    """Abstract base class representing a bandit with probability-based arm pulling mechanics."""
     @abstractmethod
     def __init__(self, p):
         # Initializing the bandit with a probability distribution p
@@ -50,13 +62,24 @@
 
     @abstractmethod
     def pull(self):
+        """
+        Simulate the action of pulling an arm of the bandit.
+
+        Returns:
+            int: The index of the arm pulled.
+        """
         pass
 
     @abstractmethod
     def update(self, arm, reward):
+        """
+        Update the internal state after an arm is pulled.
+
+        Args:
+            arm (int): The index of the arm that was pulled.
+            reward (float): The reward received from pulling the arm.
+        """
         pass
 
     def experiment(self, num_trials):
+        """
+        Conduct an experiment consisting of a specified number of trials.
+
+        Args:
+            num_trials (int): The number of trials to run.
+        """
         # Running an experiment with num_trials iterations
         for _ in range(num_trials):
             arm = self.pull()
@@ -67,6 +90,12 @@
             self.update(arm, reward)  # Updating bandit's state
 
     def report(self, algorithm):
+        """
+        Generate a report of the experiment's outcomes and log the results.
+
+        Args:
+            algorithm (str): The name of the algorithm used for the experiment.
+        """
         # Reporting results of the experiment
         with open(f'{algorithm}_results.csv', mode='w', newline='') as file:
             writer = csv.writer(file)
@@ -80,6 +109,8 @@
 
 
 class EpsilonGreedy(Bandit):
+    """Implementation of the Epsilon-Greedy strategy for the multi-armed bandit problem."""
     def __init__(self, p, initial_epsilon):
         super().__init__(p)
         self.epsilon = initial_epsilon  # Initializing epsilon
@@ -90,18 +121,28 @@
         return 'EpsilonGreedy'
 
     def pull(self):
+        """
+        Pull an arm based on the epsilon-greedy strategy.
+
+        Returns:
+            int: The index of the arm pulled.
+        """
         if random.random() < self.epsilon:
             return random.randint(0, len(self.p) - 1)
         else:
             return self.q_values.index(max(self.q_values))
 
     def update(self, arm, reward):
+        """
+        Update the estimated values (Q-values) based on the received reward.
+
+        Args:
+            arm (int): The index of the arm pulled.
+            reward (float): The reward received from the arm.
+        """
         self.action_counts[arm] += 1  # Incrementing action count
         self.q_values[arm] += (reward - self.q_values[arm]) / self.action_counts[arm]  # Updating q-value
         self.epsilon = 1 / (sum(self.action_counts) + 1)  # Decay epsilon
 
 
 class ThompsonSampling(Bandit):
+    """Implementation of the Thompson Sampling strategy for the multi-armed bandit problem."""
     def __init__(self, p, precision):
         super().__init__(p)
         self.precision = precision  # Setting precision
@@ -112,10 +153,18 @@
         return 'ThompsonSampling'
 
     def pull(self):
+        """
+        Pull an arm based on Thompson Sampling strategy by drawing from a beta distribution.
+
+        Returns:
+            int: The index of the
